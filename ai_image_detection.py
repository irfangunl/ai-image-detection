"""
AI Image Detection Project
Yapay Zeka TarafÄ±ndan OluÅŸturulmuÅŸ GÃ¶rsel Tespit Projesi

Bu projede, bir gÃ¶rselin gerÃ§ek mi yoksa yapay zeka tarafÄ±ndan mÄ± oluÅŸturulduÄŸunu 
tespit eden bir sinir aÄŸÄ± modeli geliÅŸtirilmiÅŸtir.

Video Analizi: Videolardan 5 farklÄ± frame Ã§Ä±karÄ±larak her biri ayrÄ± ayrÄ± analiz 
edilecek ve sonuÃ§lar birleÅŸtirilerek karar verilecektir.
"""

# ============================================
# 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi
# ============================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Dosya seÃ§me iÃ§in
from tkinter import Tk, filedialog

# Keras/TensorFlow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

print(f"TensorFlow Versiyonu: {tf.__version__}")
print(f"GPU KullanÄ±labilir mi: {tf.config.list_physical_devices('GPU')}")


# ============================================
# 2. Veri Setinin HazÄ±rlanmasÄ±
# ============================================

"""
Veri Seti: CIFAKE - Real and AI-Generated Synthetic Images (Kaggle)

Bu veri seti:
- 60,000 gerÃ§ek gÃ¶rsel (CIFAR-10'dan)
- 60,000 yapay zeka Ã¼retimi gÃ¶rsel (Stable Diffusion v1.4)
- Her gÃ¶rsel 32x32 piksel boyutunda

Link: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images
"""

# Veri yolu ayarlarÄ± (Kaggle'dan indirdikten sonra gÃ¼ncelleyin)
DATA_PATH = 'cifake/'  # Veri setinin bulunduÄŸu klasÃ¶r
IMG_SIZE = 64  # GÃ¶rselleri yeniden boyutlandÄ±rma
BATCH_SIZE = 32

# EÄŸitim modunu kullanÄ±cÄ±dan al
print("\n" + "="*50)
print("EÄÄ°TÄ°M MODU SEÃ‡Ä°MÄ°")
print("="*50)
print("1. Demo EÄŸitim - HÄ±zlÄ± test iÃ§in (Her sÄ±nÄ±ftan 1000 gÃ¶rsel, ~5 epoch)")
print("2. Tam EÄŸitim - YÃ¼ksek performans iÃ§in (Her sÄ±nÄ±ftan 10000 gÃ¶rsel, ~20 epoch)")
print("="*50)

while True:
    mode = input("\nSeÃ§iminiz (1 veya 2): ").strip()
    if mode in ['1', '2']:
        break
    print("HatalÄ± seÃ§im! LÃ¼tfen 1 veya 2 girin.")

if mode == '1':
    SAMPLE_SIZE = 1000
    EPOCHS = 10
    print("\nâœ“ Demo EÄŸitim modu seÃ§ildi")
    print(f"  - Her sÄ±nÄ±ftan {SAMPLE_SIZE} gÃ¶rsel kullanÄ±lacak")
    print(f"  - {EPOCHS} epoch eÄŸitim yapÄ±lacak")
    print(f"  - Tahmini sÃ¼re: 5-10 dakika\n")
else:
    SAMPLE_SIZE = 10000
    EPOCHS = 20
    print("\nâœ“ Tam EÄŸitim modu seÃ§ildi")
    print(f"  - Her sÄ±nÄ±ftan {SAMPLE_SIZE} gÃ¶rsel kullanÄ±lacak")
    print(f"  - {EPOCHS} epoch eÄŸitim yapÄ±lacak")
    print(f"  - Tahmini sÃ¼re: 30-60 dakika\n")


# ============================================
# 3. GÃ¶rsellerin YÃ¼klenmesi ve Ã–n Ä°ÅŸleme
# ============================================

def load_dataset(data_path, img_size=64, sample_size=10000):
    """
    Veri setini yÃ¼kler ve Ã¶n iÅŸleme yapar
    
    Args:
        data_path: Veri setinin yolu
        img_size: GÃ¶rsellerin boyutu
        sample_size: Her sÄ±nÄ±ftan kaÃ§ gÃ¶rsel alÄ±nacak (hÄ±z iÃ§in)
    
    Returns:
        X, y: GÃ¶rsel verileri ve etiketleri
    """
    X = []
    y = []
    
    # GerÃ§ek gÃ¶rseller (label = 0)
    real_path = os.path.join(data_path, 'train', 'REAL')
    if os.path.exists(real_path):
        real_images = os.listdir(real_path)[:sample_size]
        print(f"GerÃ§ek gÃ¶rseller yÃ¼kleniyor: {len(real_images)} adet")
        
        for img_name in real_images:
            img_path = os.path.join(real_path, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (img_size, img_size))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                X.append(img)
                y.append(0)  # GerÃ§ek = 0
    
    # AI Ã¼retimi gÃ¶rseller (label = 1)
    fake_path = os.path.join(data_path, 'train', 'FAKE')
    if os.path.exists(fake_path):
        fake_images = os.listdir(fake_path)[:sample_size]
        print(f"AI Ã¼retimi gÃ¶rseller yÃ¼kleniyor: {len(fake_images)} adet")
        
        for img_name in fake_images:
            img_path = os.path.join(fake_path, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (img_size, img_size))
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                X.append(img)
                y.append(1)  # AI Ã¼retimi = 1
    
    X = np.array(X, dtype='float32') / 255.0  # Normalizasyon
    y = np.array(y)
    
    print(f"\nToplam gÃ¶rsel sayÄ±sÄ±: {len(X)}")
    print(f"GerÃ§ek gÃ¶rseller: {np.sum(y == 0)}")
    print(f"AI Ã¼retimi gÃ¶rseller: {np.sum(y == 1)}")
    
    return X, y


# ============================================
# 4. CNN Modelinin OluÅŸturulmasÄ±
# ============================================

def create_model(input_shape=(64, 64, 3)):
    """
    AI gÃ¶rsel tespit modeli oluÅŸturur
    
    Mimari:
    - 3 Convolutional blok (Conv2D + BatchNorm + MaxPooling + Dropout)
    - Flatten
    - 2 Dense katman
    - Binary classification (sigmoid)
    """
    model = Sequential([
        # Ä°lk Conv BloÄŸu
        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
        BatchNormalization(),
        Conv2D(32, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # Ä°kinci Conv BloÄŸu
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # ÃœÃ§Ã¼ncÃ¼ Conv BloÄŸu
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # Dense Katmanlar
        Flatten(),
        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(128, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(1, activation='sigmoid')  # Binary classification
    ])
    
    # Model derleme
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model


# ============================================
# 5. GÃ¶rsel Tahmin Fonksiyonu
# ============================================

def predict_single_image(image_path, model, img_size=64):
    """
    Tek bir gÃ¶rsel iÃ§in tahmin yapar
    
    Args:
        image_path: GÃ¶rsel dosya yolu
        model: EÄŸitilmiÅŸ model
        img_size: GÃ¶rsel boyutu
    
    Returns:
        prediction: Tahmin (0: GerÃ§ek, 1: AI)
        confidence: GÃ¼ven skoru
    """
    # GÃ¶rseli oku
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Yeniden boyutlandÄ±r ve normalize et
    img_resized = cv2.resize(img, (img_size, img_size))
    img_normalized = img_resized / 255.0
    
    # Tahmin
    pred_prob = model.predict(np.expand_dims(img_normalized, axis=0), verbose=0)[0][0]
    prediction = 1 if pred_prob > 0.5 else 0
    confidence = pred_prob if prediction else 1 - pred_prob
    
    # GÃ¶rselleÅŸtirme
    plt.figure(figsize=(8, 6))
    plt.imshow(img)
    
    title = f"Tahmin: {'AI Ãœretimi' if prediction else 'GerÃ§ek GÃ¶rsel'}\n"
    title += f"GÃ¼ven Skoru: %{confidence*100:.1f}"
    
    plt.title(title, fontsize=14, fontweight='bold')
    plt.axis('off')
    plt.show()
    
    return prediction, confidence


# ============================================
# 6. Ana EÄŸitim ve DeÄŸerlendirme Fonksiyonu
# ============================================

def train_and_evaluate():
    """
    Model eÄŸitimi ve deÄŸerlendirmesini gerÃ§ekleÅŸtirir
    """
    print("\n" + "="*50)
    print("VERÄ° SETÄ° YÃœKLENÄ°YOR")
    print("="*50)
    
    # Veri setini yÃ¼kle
    X, y = load_dataset(DATA_PATH, img_size=IMG_SIZE, sample_size=SAMPLE_SIZE)
    
    # EÄŸitim ve test setlerine ayÄ±r
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nEÄŸitim seti: {X_train.shape}")
    print(f"Test seti: {X_test.shape}")
    
    # Veri gÃ¶rselleÅŸtirme
    print("\nÃ–rnek gÃ¶rseller gÃ¶rselleÅŸtiriliyor...")
    plt.figure(figsize=(15, 6))
    
    # GerÃ§ek gÃ¶rseller
    for i in range(5):
        idx = np.where(y_train == 0)[0][i]
        plt.subplot(2, 5, i+1)
        plt.imshow(X_train[idx])
        plt.title('GerÃ§ek GÃ¶rsel', fontsize=10)
        plt.axis('off')
    
    # AI Ã¼retimi gÃ¶rseller
    for i in range(5):
        idx = np.where(y_train == 1)[0][i]
        plt.subplot(2, 5, i+6)
        plt.imshow(X_train[idx])
        plt.title('AI Ãœretimi', fontsize=10)
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('sample_images.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Model oluÅŸturma
    print("\n" + "="*50)
    print("MODEL OLUÅTURULUYOR")
    print("="*50)
    
    model = create_model(input_shape=(IMG_SIZE, IMG_SIZE, 3))
    model.summary()
    
    # Data augmentation
    print("\nData augmentation hazÄ±rlanÄ±yor...")
    datagen = ImageDataGenerator(
        rotation_range=15,
        width_shift_range=0.1,
        height_shift_range=0.1,
        horizontal_flip=True,
        zoom_range=0.1
    )
    datagen.fit(X_train)
    
    # Model eÄŸitimi
    print("\n" + "="*50)
    print("MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR")
    print("="*50)
    
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)
    
    history = model.fit(
        datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
        epochs=EPOCHS,
        validation_data=(X_test, y_test),
        callbacks=[early_stop, reduce_lr],
        verbose=1
    )
    
    # EÄŸitim grafiklerini gÃ¶rselleÅŸtirme
    print("\nEÄŸitim grafikleri oluÅŸturuluyor...")
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Loss grafiÄŸi
    axes[0].plot(history.history['loss'], label='EÄŸitim Loss', linewidth=2)
    axes[0].plot(history.history['val_loss'], label='Validasyon Loss', linewidth=2)
    axes[0].set_title('Model Loss GrafiÄŸi', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Accuracy grafiÄŸi
    axes[1].plot(history.history['accuracy'], label='EÄŸitim Accuracy', linewidth=2)
    axes[1].plot(history.history['val_accuracy'], label='Validasyon Accuracy', linewidth=2)
    axes[1].set_title('Model Accuracy GrafiÄŸi', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Model deÄŸerlendirmesi
    print("\n" + "="*50)
    print("MODEL DEÄERLENDÄ°RMESÄ°")
    print("="*50)
    
    y_pred_prob = model.predict(X_test)
    y_pred = (y_pred_prob > 0.5).astype(int).flatten()
    
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    print("\n" + "="*50)
    print("MODEL PERFORMANS METRÄ°KLERÄ°")
    print("="*50)
    print(f"Accuracy  (DoÄŸruluk): {accuracy*100:.2f}%")
    print(f"Precision (Kesinlik): {precision*100:.2f}%")
    print(f"Recall    (DuyarlÄ±lÄ±k): {recall*100:.2f}%")
    print(f"F1-Score: {f1*100:.2f}%")
    print("="*50)
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
                xticklabels=['GerÃ§ek', 'AI Ãœretimi'],
                yticklabels=['GerÃ§ek', 'AI Ãœretimi'])
    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
    plt.ylabel('GerÃ§ek Etiket')
    plt.xlabel('Tahmin Edilen Etiket')
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['GerÃ§ek', 'AI Ãœretimi']))
    
    # Ã–rnek tahminler
    print("\nÃ–rnek tahminler gÃ¶rselleÅŸtiriliyor...")
    plt.figure(figsize=(15, 10))
    
    for i in range(15):
        idx = np.random.randint(0, len(X_test))
        img = X_test[idx]
        true_label = y_test[idx]
        
        # Tahmin
        pred_prob = model.predict(np.expand_dims(img, axis=0), verbose=0)[0][0]
        pred_label = 1 if pred_prob > 0.5 else 0
        
        # GÃ¶rselleÅŸtirme
        plt.subplot(3, 5, i+1)
        plt.imshow(img)
        
        # BaÅŸlÄ±k rengi (doÄŸru: yeÅŸil, yanlÄ±ÅŸ: kÄ±rmÄ±zÄ±)
        color = 'green' if pred_label == true_label else 'red'
        
        title = f"GerÃ§ek: {'AI' if true_label else 'GerÃ§ek'}\n"
        title += f"Tahmin: {'AI' if pred_label else 'GerÃ§ek'}\n"
        title += f"(%{pred_prob*100:.1f})"
        
        plt.title(title, fontsize=8, color=color, fontweight='bold')
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Modeli kaydetme
    print("\nModel kaydediliyor...")
    model.save('ai_image_detector.h5')
    print("Model 'ai_image_detector.h5' olarak kaydedildi.")
    
    return model


# ============================================
# 7. Ana Program
# ============================================

if __name__ == "__main__":
    print("="*50)
    print("AI IMAGE DETECTION PROJECT")
    print("Yapay Zeka GÃ¶rsel Tespit Projesi")
    print("="*50)
    
    # Model eÄŸitimi ve deÄŸerlendirmesi
    model = train_and_evaluate()
    
    print("\n" + "="*50)
    print("EÄÄ°TÄ°M TAMAMLANDI!")
    print("="*50)
    
    # KullanÄ±cÄ±dan gÃ¶rsel seÃ§mesini iste
    print("\n" + "="*50)
    print("GÃ–RSEL TEST MODU")
    print("="*50)
    print("\nÅimdi kendi gÃ¶rselinizi test edebilirsiniz!")
    print("Dosya seÃ§me penceresi aÃ§Ä±lacak...")
    print("Veya 'q' yazarak Ã§Ä±kÄ±ÅŸ yapabilirsiniz.")
    print("="*50)
    
    while True:
        choice = input("\nGÃ¶rsel seÃ§mek iÃ§in ENTER'a basÄ±n (veya 'q' ile Ã§Ä±kÄ±ÅŸ): ").strip().lower()
        
        if choice == 'q':
            print("\nProgram sonlandÄ±rÄ±lÄ±yor...")
            break
        
        # Dosya seÃ§me penceresini aÃ§
        print("\nğŸ“‚ Dosya seÃ§me penceresi aÃ§Ä±lÄ±yor...")
        root = Tk()
        root.withdraw()  # Ana pencereyi gizle
        root.attributes('-topmost', True)  # Pencereyi en Ã¼ste getir
        
        image_path = filedialog.askopenfilename(
            title="Test etmek istediÄŸiniz gÃ¶rseli seÃ§in",
            filetypes=[
                ("GÃ¶rsel DosyalarÄ±", "*.jpg *.jpeg *.png *.bmp *.gif"),
                ("TÃ¼m Dosyalar", "*.*")
            ]
        )
        
        root.destroy()
        
        # KullanÄ±cÄ± iptal etti
        if not image_path:
            print("âŒ Dosya seÃ§ilmedi.")
            continue
        
        if not os.path.exists(image_path):
            print(f"\nâŒ HATA: GÃ¶rsel bulunamadÄ±: {image_path}")
            print("LÃ¼tfen geÃ§erli bir dosya yolu girin.")
            continue
        
        try:
            print(f"\nğŸ” GÃ¶rsel analiz ediliyor: {image_path}")
            print("-" * 50)
            
            prediction, confidence = predict_single_image(image_path, model, img_size=IMG_SIZE)
            
            print("\n" + "="*50)
            print("SONUÃ‡")
            print("="*50)
            if prediction == 0:
                print(f"âœ… Bu gÃ¶rsel GERÃ‡EK bir gÃ¶rsel")
            else:
                print(f"ğŸ¤– Bu gÃ¶rsel AI TARAFINDAN ÃœRETÄ°LMÄ°Å")
            print(f"GÃ¼ven Skoru: %{confidence*100:.2f}")
            print("="*50)
            
            # BaÅŸka gÃ¶rsel test etmek isteyip istemediÄŸini sor
            another = input("\nBaÅŸka bir gÃ¶rsel test etmek ister misiniz? (E/H): ").strip().lower()
            if another != 'e':
                print("\nProgram sonlandÄ±rÄ±lÄ±yor...")
                break
                
        except Exception as e:
            print(f"\nâŒ HATA: GÃ¶rsel iÅŸlenirken bir hata oluÅŸtu: {str(e)}")
            print("LÃ¼tfen baÅŸka bir gÃ¶rsel deneyin.")
    
    print("\n" + "="*50)
    print("TeÅŸekkÃ¼rler! ğŸ‘‹")
    print("="*50)

